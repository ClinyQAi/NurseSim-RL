{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä IJHPM Manuscript Validation: 50-Scenario Benchmark\n",
                "\n",
                "**Purpose:** Run NurseSim-Triage evaluation on 50 standardized clinical scenarios for the IJHPM manuscript.\n",
                "\n",
                "**Output:** Accuracy metrics, category-level performance, and manuscript-ready tables.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q gradio_client pandas matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import re\n",
                "import time\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from gradio_client import Client\n",
                "from datetime import datetime\n",
                "\n",
                "print(\"‚úÖ Libraries loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Validation Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download val.jsonl from GitHub\n",
                "!wget -q https://raw.githubusercontent.com/ClinyQAi/NurseSim-RL/main/data/val.jsonl -O val.jsonl\n",
                "\n",
                "# Load scenarios\n",
                "scenarios = []\n",
                "with open('val.jsonl', 'r') as f:\n",
                "    for line in f:\n",
                "        if line.strip():\n",
                "            scenarios.append(json.loads(line))\n",
                "\n",
                "# Use first 50 for validation\n",
                "scenarios = scenarios[:50]\n",
                "print(f\"‚úÖ Loaded {len(scenarios)} scenarios\")\n",
                "\n",
                "# Show category distribution\n",
                "cat_counts = {}\n",
                "for s in scenarios:\n",
                "    cat = s.get('category', 'Unknown')\n",
                "    cat_counts[cat] = cat_counts.get(cat, 0) + 1\n",
                "\n",
                "cat_names = {1:'Immediate', 2:'Very Urgent', 3:'Urgent', 4:'Standard', 5:'Non-Urgent'}\n",
                "print(\"\\nCategory Distribution:\")\n",
                "for cat in sorted(cat_counts.keys()):\n",
                "    print(f\"  Category {cat} ({cat_names.get(cat, 'Unknown')}): {cat_counts[cat]} cases\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Connect to NurseSim-Triage Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Connect to Hugging Face Space\n",
                "print(\"Connecting to NurseSim-Triage...\")\n",
                "try:\n",
                "    client = Client(\"NurseCitizenDeveloper/NurseSim-Triage-Demo\")\n",
                "    print(\"‚úÖ Connected to NurseSim-Triage\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Connection failed: {e}\")\n",
                "    print(\"\\nTroubleshooting:\")\n",
                "    print(\"1. Check if the Space is running: https://huggingface.co/spaces/NurseCitizenDeveloper/NurseSim-Triage-Demo\")\n",
                "    print(\"2. The Space may need to 'wake up' - try refreshing the page first\")\n",
                "    client = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def parse_scenario(scenario):\n",
                "    \"\"\"Extract vitals from scenario input text\"\"\"\n",
                "    input_text = scenario['input']\n",
                "    \n",
                "    # Extract chief complaint\n",
                "    complaint_match = re.search(r'Chief Complaint: \"(.+?)\"', input_text)\n",
                "    complaint = complaint_match.group(1) if complaint_match else input_text[:100]\n",
                "    \n",
                "    # Extract vitals\n",
                "    hr_match = re.search(r'HR: (\\d+)', input_text)\n",
                "    bp_match = re.search(r'BP: ([\\d/]+)', input_text)\n",
                "    spo2_match = re.search(r'SpO2: (\\d+)', input_text)\n",
                "    temp_match = re.search(r'Temp: ([\\d.]+)', input_text)\n",
                "    \n",
                "    return {\n",
                "        'complaint': complaint,\n",
                "        'hr': int(hr_match.group(1)) if hr_match else 80,\n",
                "        'bp': bp_match.group(1) if bp_match else '120/80',\n",
                "        'spo2': int(spo2_match.group(1)) if spo2_match else 98,\n",
                "        'temp': float(temp_match.group(1)) if temp_match else 37.0,\n",
                "        'expected': scenario.get('category', -1)\n",
                "    }\n",
                "\n",
                "def extract_category(response_text):\n",
                "    \"\"\"Extract triage category 1-5 from model response\"\"\"\n",
                "    text = str(response_text).lower()\n",
                "    \n",
                "    # Check for category words\n",
                "    if 'category: 1' in text or 'immediate' in text and 'red' in text:\n",
                "        return 1\n",
                "    if 'category: 2' in text or 'very urgent' in text:\n",
                "        return 2\n",
                "    if 'category: 3' in text or ('urgent' in text and 'very' not in text and 'non' not in text):\n",
                "        return 3\n",
                "    if 'category: 4' in text or 'standard' in text:\n",
                "        return 4\n",
                "    if 'category: 5' in text or 'non-urgent' in text or 'non urgent' in text:\n",
                "        return 5\n",
                "    \n",
                "    # Look for number pattern\n",
                "    match = re.search(r'category[:\\s]*([1-5])', text)\n",
                "    if match:\n",
                "        return int(match.group(1))\n",
                "    \n",
                "    return -1\n",
                "\n",
                "def query_model(parsed):\n",
                "    \"\"\"Query NurseSim-Triage model\"\"\"\n",
                "    if client is None:\n",
                "        return -1, \"No client\"\n",
                "    \n",
                "    try:\n",
                "        result = client.predict(\n",
                "            complaint=parsed['complaint'],\n",
                "            hr=float(parsed['hr']),\n",
                "            bp=parsed['bp'],\n",
                "            spo2=float(parsed['spo2']),\n",
                "            temp=float(parsed['temp']),\n",
                "            api_name=\"/gradio_predict\"\n",
                "        )\n",
                "        return extract_category(str(result)), str(result)[:200]\n",
                "    except Exception as e:\n",
                "        return -1, str(e)[:100]\n",
                "\n",
                "print(\"‚úÖ Functions ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üî¨ Running 50-Scenario Evaluation...\\n\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "results = []\n",
                "for i, scenario in enumerate(scenarios):\n",
                "    parsed = parse_scenario(scenario)\n",
                "    predicted, response = query_model(parsed)\n",
                "    expected = parsed['expected']\n",
                "    \n",
                "    match = \"‚úì\" if predicted == expected else \"‚úó\"\n",
                "    print(f\"[{i+1:2d}/50] Expected: {expected} | Predicted: {predicted} {match}\")\n",
                "    \n",
                "    results.append({\n",
                "        'scenario_id': i + 1,\n",
                "        'complaint': parsed['complaint'][:50],\n",
                "        'expected': expected,\n",
                "        'predicted': predicted,\n",
                "        'exact_match': predicted == expected,\n",
                "        'within_1': abs(predicted - expected) <= 1 if predicted > 0 else False,\n",
                "        'under_triage': predicted > expected if predicted > 0 else False,\n",
                "        'over_triage': predicted < expected if predicted > 0 else False\n",
                "    })\n",
                "    \n",
                "    time.sleep(1.5)  # Rate limiting\n",
                "\n",
                "df = pd.DataFrame(results)\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ Evaluation Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Calculate Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter valid responses\n",
                "valid = df[df['predicted'] > 0]\n",
                "n_valid = len(valid)\n",
                "n_total = len(df)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üìä NURSESIM-TRIAGE VALIDATION RESULTS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nValid Responses: {n_valid}/{n_total} ({n_valid/n_total*100:.0f}%)\\n\")\n",
                "\n",
                "# Overall Metrics\n",
                "exact_accuracy = valid['exact_match'].mean() * 100\n",
                "within_1_accuracy = valid['within_1'].mean() * 100\n",
                "under_triage_rate = valid['under_triage'].mean() * 100\n",
                "over_triage_rate = valid['over_triage'].mean() * 100\n",
                "\n",
                "print(\"OVERALL PERFORMANCE:\")\n",
                "print(f\"  Exact Match Accuracy:  {valid['exact_match'].sum()}/{n_valid} ({exact_accuracy:.1f}%)\")\n",
                "print(f\"  Within ¬±1 Category:    {valid['within_1'].sum()}/{n_valid} ({within_1_accuracy:.1f}%)\")\n",
                "print(f\"  Under-triage Rate:     {valid['under_triage'].sum()}/{n_valid} ({under_triage_rate:.1f}%)\")\n",
                "print(f\"  Over-triage Rate:      {valid['over_triage'].sum()}/{n_valid} ({over_triage_rate:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Performance by Category (for manuscript Table 1)\n",
                "print(\"\\n\" + \"-\"*60)\n",
                "print(\"PERFORMANCE BY MTS CATEGORY:\")\n",
                "print(\"-\"*60)\n",
                "\n",
                "cat_names = {\n",
                "    1: 'Immediate (Red)',\n",
                "    2: 'Very Urgent (Orange)', \n",
                "    3: 'Urgent (Yellow)',\n",
                "    4: 'Standard (Green)',\n",
                "    5: 'Non-Urgent (Blue)'\n",
                "}\n",
                "\n",
                "cat_results = []\n",
                "for cat in [1, 2, 3, 4, 5]:\n",
                "    subset = valid[valid['expected'] == cat]\n",
                "    if len(subset) > 0:\n",
                "        accuracy = subset['exact_match'].mean() * 100\n",
                "        n = len(subset)\n",
                "        correct = subset['exact_match'].sum()\n",
                "        cat_results.append({\n",
                "            'Category': cat,\n",
                "            'Name': cat_names.get(cat, 'Unknown'),\n",
                "            'N': n,\n",
                "            'Correct': correct,\n",
                "            'Accuracy': accuracy\n",
                "        })\n",
                "        print(f\"  Category {cat} ({cat_names.get(cat, 'Unknown')}): {correct}/{n} ({accuracy:.0f}%)\")\n",
                "\n",
                "cat_df = pd.DataFrame(cat_results)\n",
                "print(\"\\n‚úÖ Category breakdown complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Safety Analysis (Critical for manuscript)\n",
                "print(\"\\n\" + \"-\"*60)\n",
                "print(\"SAFETY ANALYSIS (Critical Category Detection):\")\n",
                "print(\"-\"*60)\n",
                "\n",
                "# Category 1 (Immediate) - most critical\n",
                "cat1 = valid[valid['expected'] == 1]\n",
                "cat1_correct = cat1['exact_match'].sum() if len(cat1) > 0 else 0\n",
                "cat1_total = len(cat1)\n",
                "cat1_sensitivity = (cat1_correct / cat1_total * 100) if cat1_total > 0 else 0\n",
                "\n",
                "# Critical under-triage (predicting Cat 3-5 when actual is Cat 1-2)\n",
                "critical_cases = valid[valid['expected'].isin([1, 2])]\n",
                "severe_undertriage = critical_cases[critical_cases['predicted'].isin([4, 5])]\n",
                "undertriage_rate = (len(severe_undertriage) / len(critical_cases) * 100) if len(critical_cases) > 0 else 0\n",
                "\n",
                "print(f\"  Category 1 Sensitivity: {cat1_correct}/{cat1_total} ({cat1_sensitivity:.0f}%)\")\n",
                "print(f\"  Severe Under-triage (Cat 1-2 ‚Üí Cat 4-5): {len(severe_undertriage)}/{len(critical_cases)} ({undertriage_rate:.1f}%)\")\n",
                "\n",
                "if undertriage_rate == 0:\n",
                "    print(\"  ‚úÖ NO severe under-triage events detected\")\n",
                "else:\n",
                "    print(\"  ‚ö†Ô∏è Severe under-triage events require review\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Generate Manuscript-Ready Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create visualization\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Chart 1: Accuracy by Category\n",
                "ax1 = axes[0]\n",
                "colors = ['#dc2626', '#f97316', '#eab308', '#22c55e', '#3b82f6']\n",
                "cats = [c['Category'] for c in cat_results]\n",
                "accs = [c['Accuracy'] for c in cat_results]\n",
                "bars = ax1.bar(cats, accs, color=colors[:len(cats)])\n",
                "ax1.set_xlabel('MTS Category')\n",
                "ax1.set_ylabel('Accuracy (%)')\n",
                "ax1.set_title('Triage Accuracy by MTS Category')\n",
                "ax1.set_ylim(0, 100)\n",
                "ax1.set_xticks([1, 2, 3, 4, 5])\n",
                "for bar, val in zip(bars, accs):\n",
                "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
                "             f'{val:.0f}%', ha='center', fontweight='bold')\n",
                "\n",
                "# Chart 2: Overall Metrics\n",
                "ax2 = axes[1]\n",
                "metrics = ['Exact Match', 'Within ¬±1', 'Under-triage', 'Over-triage']\n",
                "values = [exact_accuracy, within_1_accuracy, under_triage_rate, over_triage_rate]\n",
                "colors2 = ['#22c55e', '#3b82f6', '#ef4444', '#f97316']\n",
                "bars2 = ax2.bar(metrics, values, color=colors2)\n",
                "ax2.set_ylabel('Percentage (%)')\n",
                "ax2.set_title('Overall Performance Metrics')\n",
                "ax2.set_ylim(0, 100)\n",
                "for bar, val in zip(bars2, values):\n",
                "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
                "             f'{val:.1f}%', ha='center', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('ijhpm_validation_results.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "print(\"\\n‚úÖ Saved: ijhpm_validation_results.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate Markdown Report for Manuscript\n",
                "report = f\"\"\"# NurseSim-Triage Validation Results\n",
                "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
                "**Dataset:** 50 standardized clinical scenarios from val.jsonl\n",
                "\n",
                "## Summary\n",
                "\n",
                "| Metric | Result |\n",
                "|--------|--------|\n",
                "| Sample Size | {n_valid} scenarios |\n",
                "| Exact Match Accuracy | {exact_accuracy:.1f}% |\n",
                "| Within ¬±1 Category | {within_1_accuracy:.1f}% |\n",
                "| Under-triage Rate | {under_triage_rate:.1f}% |\n",
                "| Over-triage Rate | {over_triage_rate:.1f}% |\n",
                "\n",
                "## Table 1: Performance by MTS Category\n",
                "\n",
                "| Category | Description | n | Correct | Accuracy |\n",
                "|----------|-------------|---|---------|----------|\n",
                "\"\"\"\n",
                "\n",
                "for c in cat_results:\n",
                "    report += f\"| {c['Category']} | {c['Name']} | {c['N']} | {c['Correct']} | {c['Accuracy']:.0f}% |\\n\"\n",
                "\n",
                "report += f\"\"\"\n",
                "## Safety Analysis\n",
                "\n",
                "| Metric | Result |\n",
                "|--------|--------|\n",
                "| Category 1 Sensitivity | {cat1_sensitivity:.0f}% ({cat1_correct}/{cat1_total}) |\n",
                "| Severe Under-triage (Cat 1-2 ‚Üí Cat 4-5) | {undertriage_rate:.1f}% ({len(severe_undertriage)}/{len(critical_cases)}) |\n",
                "\n",
                "## Notes for Manuscript\n",
                "\n",
                "- **Methodology:** Evaluated on {n_valid} standardized clinical scenarios from a held-out validation set.\n",
                "- **Ground Truth:** Each scenario was assigned an expected MTS category based on clinical guidelines.\n",
                "- **Safety Focus:** Under-triage of critical patients (Category 1-2) is penalized more heavily than over-triage.\n",
                "\n",
                "---\n",
                "*NurseSim-Triage | IJHPM Manuscript Validation*\n",
                "\"\"\"\n",
                "\n",
                "print(report)\n",
                "\n",
                "with open('ijhpm_validation_report.md', 'w') as f:\n",
                "    f.write(report)\n",
                "print(\"\\n‚úÖ Saved: ijhpm_validation_report.md\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save raw results\n",
                "df.to_csv('ijhpm_validation_raw.csv', index=False)\n",
                "print(\"‚úÖ Saved: ijhpm_validation_raw.csv\")\n",
                "\n",
                "# Download files\n",
                "print(\"\\nüì• Download these files for your manuscript:\")\n",
                "print(\"   1. ijhpm_validation_report.md - Results summary\")\n",
                "print(\"   2. ijhpm_validation_results.png - Charts\")\n",
                "print(\"   3. ijhpm_validation_raw.csv - Raw data\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}